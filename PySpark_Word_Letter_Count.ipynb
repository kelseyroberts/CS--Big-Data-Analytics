{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WORD COUNTS\n",
    "\n",
    "import sys\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "# Initialize spark configuration and context\n",
    "conf = SparkConf()\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "# Read from text file, split each line into \"words\" by any whitespace with a string split\n",
    "lines = sc.textFile(\"pg100.txt\")\n",
    "words = lines.flatMap(lambda line: line.split())\n",
    "\n",
    "# Filter non-alpha characters, then convert them to lowercase\n",
    "words = words.filter(lambda word: word.isalpha()) \\\n",
    "               .map(lambda word: word.lower())\n",
    "\n",
    "# Map each word to a key-value pair, with value 1\n",
    "pairs = words.map(lambda word: (word, 1))\n",
    "\n",
    "# Reduce by key, effectively summing every tuples values into a single reduction for each word\n",
    "counts = pairs.reduceByKey(lambda a, b:a+b)\n",
    "\n",
    "# Save to output directory, end context\n",
    "counts.saveAsTextFile(\"Word_Count\")\n",
    "sc.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##FINAL LETTER COUNT\n",
    "\n",
    "import sys\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "# Initialize spark configuration and context\n",
    "conf = SparkConf()\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "# Read from text file, split each line into \"words\" by any whitespace \n",
    "lines = sc.textFile(\"pg100.txt\")\n",
    "words = lines.flatMap(lambda line: line.split())\n",
    "\n",
    "# Create letters by taking [0] aka the first letter of the word, Filter non-alpha characters, and convert them to lowercase\n",
    "letters = words.filter(lambda letter: letter.isalpha()) \\\n",
    "               .map(lambda word: word[0].lower())\n",
    "\n",
    "# Map each letter to a key-value pair, with value 1\n",
    "pairs = letters.map(lambda letter: (letter, 1))\n",
    "\n",
    "# Reduce by key, effectively summing every tuples values into a single reduction for each letter\n",
    "counts = pairs.reduceByKey(lambda n1, n2: n1 + n2)\n",
    "\n",
    "# Save to output directory, end context\n",
    "counts.saveAsTextFile(\"Letter_Count\")\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
